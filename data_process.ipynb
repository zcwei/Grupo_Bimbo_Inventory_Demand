{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/anaconda/lib/python2.7/site-packages/matplotlib/font_manager.py:273: UserWarning: Matplotlib is building the font cache using fc-list. This may take a moment.\n",
      "  warnings.warn('Matplotlib is building the font cache using fc-list. This may take a moment.')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##load the data , it is huge. Do not read again \n",
    "train = pd.read_csv(\"train.csv\")\n",
    "test = pd.read_csv(\"test.csv\")\n",
    "client_names = pd.read_csv(\"cliente_tabla.csv\")\n",
    "product_names = pd.read_csv(\"producto_tabla.csv\")\n",
    "town = pd.read_csv(\"town_state.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>week_num</th>\n",
       "      <th>sales_depot_ID</th>\n",
       "      <th>sales_channel_ID</th>\n",
       "      <th>route_ID</th>\n",
       "      <th>client_ID</th>\n",
       "      <th>product_ID</th>\n",
       "      <th>sales_unit_this_week</th>\n",
       "      <th>sales_this_week</th>\n",
       "      <th>returns_unit_next_week</th>\n",
       "      <th>returns_next_week</th>\n",
       "      <th>adjusted_demand</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>1110</td>\n",
       "      <td>7</td>\n",
       "      <td>3301</td>\n",
       "      <td>15766</td>\n",
       "      <td>1212</td>\n",
       "      <td>3</td>\n",
       "      <td>25.14</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>1110</td>\n",
       "      <td>7</td>\n",
       "      <td>3301</td>\n",
       "      <td>15766</td>\n",
       "      <td>1216</td>\n",
       "      <td>4</td>\n",
       "      <td>33.52</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1110</td>\n",
       "      <td>7</td>\n",
       "      <td>3301</td>\n",
       "      <td>15766</td>\n",
       "      <td>1238</td>\n",
       "      <td>4</td>\n",
       "      <td>39.32</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1110</td>\n",
       "      <td>7</td>\n",
       "      <td>3301</td>\n",
       "      <td>15766</td>\n",
       "      <td>1240</td>\n",
       "      <td>4</td>\n",
       "      <td>33.52</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>1110</td>\n",
       "      <td>7</td>\n",
       "      <td>3301</td>\n",
       "      <td>15766</td>\n",
       "      <td>1242</td>\n",
       "      <td>3</td>\n",
       "      <td>22.92</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   week_num  sales_depot_ID  sales_channel_ID  route_ID  client_ID  \\\n",
       "0         3            1110                 7      3301      15766   \n",
       "1         3            1110                 7      3301      15766   \n",
       "2         3            1110                 7      3301      15766   \n",
       "3         3            1110                 7      3301      15766   \n",
       "4         3            1110                 7      3301      15766   \n",
       "\n",
       "   product_ID  sales_unit_this_week  sales_this_week  returns_unit_next_week  \\\n",
       "0        1212                     3            25.14                       0   \n",
       "1        1216                     4            33.52                       0   \n",
       "2        1238                     4            39.32                       0   \n",
       "3        1240                     4            33.52                       0   \n",
       "4        1242                     3            22.92                       0   \n",
       "\n",
       "   returns_next_week  adjusted_demand  \n",
       "0                0.0                3  \n",
       "1                0.0                4  \n",
       "2                0.0                4  \n",
       "3                0.0                4  \n",
       "4                0.0                3  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columnsDict = {'Semana': 'week_num', 'Agencia_ID': 'sales_depot_ID', 'Canal_ID':'sales_channel_ID',\n",
    "               'Ruta_SAK': 'route_ID', 'Cliente_ID': 'client_ID', 'NombreCliente': 'client_name', \n",
    "               'Producto_ID': 'product_ID', 'Venta_uni_hoy': 'sales_unit_this_week', \n",
    "               'Venta_hoy': 'sales_this_week', 'Dev_uni_proxima': 'returns_unit_next_week', \n",
    "               'Dev_proxima': 'returns_next_week', 'Demanda_uni_equil': 'adjusted_demand'}\n",
    "train.rename(columns = columnsDict, inplace = True)\n",
    "test.rename(columns = columnsDict, inplace = True)\n",
    "client_names.rename(columns = columnsDict, inplace = True)\n",
    "town.rename(columns = columnsDict, inplace = True)\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "##The product in train data set is not fully present in test data. Check how many are they \n",
    "def differenceIDTwoDF(train, test):\n",
    "    test_prod_id = set(test.product_ID.unique())\n",
    "    train_prod_id = set(train.product_ID.unique())\n",
    "    intersection  = (test_prod_id & train_prod_id)\n",
    "    print('train data product id number:', len(train_prod_id))\n",
    "    print('test data product id number:', len(test_prod_id))\n",
    "    print('intersection number:', len(intersection))\n",
    "    unintersection = test_prod_id - intersection\n",
    "    print('difference:', len(unintersection), unintersection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('train data product id number:', 1799)\n",
      "('test data product id number:', 1522)\n",
      "('intersection number:', 1488)\n",
      "('difference:', 34, set([32026, 37404, 37405, 32798, 32421, 37745, 36524, 37618, 35246, 33053, 46131, 32820, 37688, 36673, 37702, 35191, 32591, 37202, 42323, 48217, 32224, 98, 31203, 37610, 31211, 46064, 37617, 37362, 37620, 31655, 37494, 37495, 37496, 37626]))\n"
     ]
    }
   ],
   "source": [
    "differenceIDTwoDF(train, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('training set number: ', 63771751)\n",
      "('test set number: ', 10408713)\n"
     ]
    }
   ],
   "source": [
    "## train data week num is from 3-9, and test week num is 10 and 11\n",
    "test_data = train[train.week_num.isin([9])]\n",
    "train_data = train[~train.week_num.isin([9])]\n",
    "print(\"training set number: \", train_data.shape[0])\n",
    "print(\"test set number: \", test_data.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('train data product id number:', 1758)\n",
      "('test data product id number:', 1566)\n",
      "('intersection number:', 1525)\n",
      "('difference:', 41, set([35713, 36995, 43398, 37639, 36873, 48138, 37264, 37139, 48023, 37402, 40987, 37149, 36131, 35240, 48297, 35761, 3509, 33208, 37689, 37690, 36671, 37403, 33735, 37576, 4169, 42192, 37587, 37590, 36699, 37468, 37469, 37470, 40929, 35304, 35306, 35310, 35441, 35442, 37363, 37242, 1277]))\n"
     ]
    }
   ],
   "source": [
    "differenceIDTwoDF(train_data, test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "##only pick 50000 users \n",
    "import random\n",
    "\n",
    "def pickRandomData(data, numPick, pool):\n",
    "    unique_prod_id = pool\n",
    "    print(\"Number of unique product id \",unique_prod_id.shape[0])\n",
    "    sel_ids = [unique_prod_id[i] for i in sorted(random.sample(range(len(unique_prod_id)), numPick)) ]\n",
    "    sel_data = data[data.product_ID.isin(sel_ids)]\n",
    "    return sel_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##random sample the data \n",
    "import random\n",
    "\n",
    "def pickRandomData(data, numPick):\n",
    "    sel_data = data.sample(numPick)\n",
    "    return sel_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "small_train = pickRandomData(train_data, 6377175)\n",
    "small_test = pickRandomData(test_data, 1040871)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('train data product id number:', 1526)\n",
      "('test data product id number:', 1292)\n",
      "('intersection number:', 1246)\n",
      "('difference:', 46, set([37379, 31621, 48138, 37139, 37402, 37403, 37149, 37153, 35110, 48039, 31669, 33208, 37689, 37690, 32223, 36671, 49989, 37576, 49993, 37578, 4301, 47066, 37590, 31716, 49754, 37469, 37470, 34783, 40929, 36995, 33381, 35304, 4220, 35306, 107, 35310, 1277, 35442, 37363, 31861, 36058, 37241, 37242, 4859, 46076, 43389]))\n"
     ]
    }
   ],
   "source": [
    "differenceIDTwoDF(small_train, small_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import cPickle as pickle\n",
    "pickle_file = 'dataset.pickle'\n",
    "\n",
    "try:\n",
    "  f = open(pickle_file, 'wb')\n",
    "  save = {\n",
    "    'small_test': small_test,\n",
    "    'small_train': small_train,\n",
    "    'client_names': client_names, \n",
    "    'town': town\n",
    "    }\n",
    "  pickle.dump(save, f, pickle.HIGHEST_PROTOCOL)\n",
    "  f.close()\n",
    "except Exception as e:\n",
    "  print('Unable to save data to', pickle_file, ':', e)\n",
    "  raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Small training set', (6377175, 11))\n",
      "('Small test set', (1040871, 11))\n",
      "('destinations', (935362, 2))\n",
      "('town', (790, 3))\n"
     ]
    }
   ],
   "source": [
    "from six.moves import cPickle as pickle\n",
    "\n",
    "pickle_file = 'dataset.pickle'\n",
    "\n",
    "with open(pickle_file, 'rb') as f:\n",
    "  save = pickle.load(f)\n",
    "  small_test = save['small_test']\n",
    "  small_train = save['small_train']\n",
    "  client_names = save['client_names']\n",
    "  town = save['town']\n",
    "  del save  # hint to help gc free up memory\n",
    "  print('Small training set', small_train.shape)\n",
    "  print('Small test set', small_test.shape)\n",
    "  print('destinations', client_names.shape)\n",
    "  print('town', town.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "###could use xgboost with the customize objective funciton\n",
    "## evalerror <- function(preds, dtrain) {\n",
    "#   labels <- getinfo(dtrain, \"label\")\n",
    "#   #preds[preds<0] <- 0\n",
    "#   preds <- abs(preds)\n",
    "#   err <- rmsell(preds, labels)\n",
    "#   return(list(metric = \"rmsell\", value = err))\n",
    "# }\n",
    "\n",
    "\n",
    "# def evalerror(preds, dtrain):\n",
    "#     labels = dtrain.get_label()\n",
    "#     assert len(preds) == len(labels)\n",
    "#     labels = labels.tolist()\n",
    "#     preds = preds.tolist()\n",
    "#     # I have added the max since applying regression we obtain negative values of preds\n",
    "#     # and therefore an error because of the logarithm\n",
    "#     terms_to_sum = [(math.log(labels[i] + 1) - math.log(max(0,preds[i]) + 1)) ** 2.0 \n",
    "#                     for i,pred in enumerate(labels)]\n",
    "#     return 'error', (sum(terms_to_sum) * (1.0/len(preds))) ** 0.5\n",
    "\n",
    "# xgclassifier = xgb.train(params, xg_train, num_round, watchlist, \n",
    "#                      early_stopping_rounds=early_stopping, \n",
    "#                      feval = evalerror, verbose_eval = 1);\n",
    "##https://www.kaggle.com/vykhand/grupo-bimbo-inventory-demand/exploring-products/discussion \n",
    "## https://gist.github.com/rowanv/f555f65721f5bf730053\n",
    "## https://www.kaggle.com/kobakhit/grupo-bimbo-inventory-demand/xgboost/comments\n",
    "\n",
    "## https://www.kaggle.com/kelexu/grupo-bimbo-inventory-demand/0-48881/code"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
